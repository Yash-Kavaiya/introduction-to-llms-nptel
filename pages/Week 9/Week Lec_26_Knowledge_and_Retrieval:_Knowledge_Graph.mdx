## Lec 26 | Knowledge and Retrieval: Knowledge Graph

# ğŸ“Š Knowledge Graphs & LLM Retrieval ğŸ§ 

## Introduction ğŸŒŸ

Welcome back to the course on Large Language Models! In this module, we'll explore **Knowledge Graphs** and their retrieval from large language models.

> ğŸ’¡ From ancient times to modern computing, humans have continuously sought ways to organize knowledge effectively.

## Historical Context ğŸ“œ

Throughout history, humans have developed various knowledge organization systems:
- ğŸ—¿ The Rosetta Stone
- ğŸ“š The Library of Alexandria
- ğŸ” Vannevar Bush's vision of the Memex machine

## Modern Knowledge Graphs ğŸŒ

In contemporary computing, knowledge organization has evolved into **Knowledge Graphs** such as:

| Knowledge Graph | Description | Notable Features |
|-----------------|-------------|------------------|
| Yago | Derived from Wikipedia | Temporal and spatial information |
| Freebase | Community-curated | Now part of Google Knowledge Graph |
| WikiData | Collaborative KB | Supports multiple languages |

## Knowledge Graph Structure ğŸ—ï¸

For our purposes, a **Knowledge Base** (or interchangeably, a **Knowledge Graph**) consists of:

- ğŸ”· **Nodes** representing entities
  - People (Barack Obama, Michelle Obama)
  - Places (Honolulu, USA)
  
- ğŸ”— **Edges** labeled with relation types
  - "born in"
  - "city of"

### KG Triple Format âš¡

A KG triple or fact follows this structure:

```
Subject â†’ Relation â†’ Object
```

For example:
- Barack Obama â†’ born in â†’ Honolulu
- Honolulu â†’ city of â†’ USA

### Visual Representation ğŸ“ˆ

```mermaid
graph LR
    BO[Barack Obama] -->|born in| HNL[Honolulu]
    HNL -->|city of| USA[USA]
    MO[Michelle Obama] -->|spouse of| BO
```

## Beyond Binary Relations ğŸ”„

While we typically work with binary relations (two entities in a relationship), we can extend beyond this format:

### N-ary Relations Example: Movies ğŸ¬

Consider a table with three columns:
- Actor
- Role
- Movie

Examples:
- Tom Hanks played Jim Lovell in Apollo 13
- Tom Cruise played Ethan Hunt in Mission Impossible

## Key Takeaways ğŸ“Œ

- Knowledge graphs organize information as entities connected by relationships
- Binary relations form the foundation (subject-relation-object)
- More complex relationships can be modeled using n-ary relations
- Modern knowledge graphs serve as structured knowledge repositories for AI systems

# ğŸ“Š Knowledge Base (KB) / Knowledge Graph (KG) Structure ğŸ§ 

## Core Components ğŸ—ï¸

The image illustrates the fundamental structure of a knowledge graph with:

### ğŸ”µ Entities as Nodes
- **Barack Obama** (person)
- **Michelle Obama** (person)
- **Honolulu** (location)
- **USA** (country)

### ğŸ”— Relations as Edges
| Source Entity | Relation | Target Entity |
|---------------|----------|--------------|
| Barack Obama | born_in | Honolulu |
| Honolulu | city_of | USA |
| Barack Obama | spouse | Michelle Obama |
| Michelle Obama | nationality | USA |

## Knowledge Representation Principles ğŸ“

> ğŸ’¡ A KB triple or 'fact' looks like a relation-typed edge (subject, relation, object)

This structure enables the representation of real-world knowledge in a machine-readable format where:
- ğŸŸ¢ **Nodes** are entities (people, places, things)
- â¡ï¸ **Edges** are relations between entities
- ğŸ”„ **Triples** capture facts as subject-relation-object statements

## Visual Structure ğŸ“ˆ

```mermaid
graph LR
    BO[Barack Obama] -->|born_in| HNL[Honolulu]
    HNL -->|city_of| USA[USA]
    BO -->|spouse| MO[Michelle Obama]
    MO -->|nationality| USA
```

## Knowledge Base Foundation ğŸŒ

As noted at the bottom of the image, this demonstrates a **knowledge base with entities and binary relations** - the fundamental structure used in systems like Yago, Freebase, and WikiData.

# ğŸŒ Beyond Binary Relations in Knowledge Graphs ğŸ“Š

## N-ary Relations Explained ğŸ”„

> ğŸ’¡ While basic knowledge graphs use binary relations (subjectâ†’relationâ†’object), real-world facts often require more complex relationship structures.

## Example 1: Presidential Terms â³

```mermaid
graph TD
    BO["Barack Obama"] -->|person| PO[("president-of")]
    USA["USA"] -->|country| PO
    Y2009["2009"] -->|start-year| PO
    Y2017["2017"] -->|end-year| PO
```

### ğŸ“‹ Table: "president-of" Relationship
| ğŸ‘¤ person | ğŸ³ï¸ country | ğŸ“… start-year | ğŸ“… end-year |
|-----------|-----------|--------------|------------|
| B.Obama   | USA       | 2009         | 2017       |
| J.Chirac  | France    | 1995         | 2007       |
| ...       | ...       | ...          | ...        |

## Example 2: Movie Roles ğŸ¬

```mermaid
graph TD
    TC["Tom Cruise"] -->|actor| AA[("acted-as")]
    MI["Mission: Impossible"] -->|movie| AA
    EH["Ethan Hunt"] -->|role| AA
```

### ğŸ“‹ Table: "acted-as" Relationship
| ğŸ­ actor    | ğŸ­ role      | ğŸ¬ movie           |
|------------|-------------|-------------------|
| Tom Hanks  | Jim Lovell  | Apollo 13         |
| Tom Cruise | Ethan Hunt  | Mission Impossible|
| ...        | ...         | ...               |

## Key Concepts ğŸ”‘

- ğŸ’ **Diamond Nodes** represent complex relationships connecting multiple entities
- ğŸ”„ **N-ary Relations** capture facts with more than two participants
- ğŸ“Š **Tabular Representation** offers an alternative way to view these relationships
- ğŸ§© **Entity Roles** define how each entity participates in the relationship

> ğŸŒŸ This approach allows knowledge graphs to represent temporal information, multi-participant events, and relationships with additional attributes.

# ğŸŒ Wikidata: Entity ("topic") Example 

## Entity Structure in Wikidata ğŸ“Š

The image demonstrates how Wikidata organizes entity information using Barack Obama as an example:

> ğŸ’¡ Wikidata assigns each entity a unique identifier to resolve ambiguity issues when names alone aren't sufficient.

### Core Components ğŸ—ï¸

| Component | Example | Purpose |
|-----------|---------|---------|
| ğŸ“ **Name** | Barack Obama | Human-readable identifier (potentially ambiguous) |
| ğŸ”‘ **Unique ID** | Q76 | Canonical machine-readable identifier |
| ğŸ“‹ **Description** | 44th president of the United States from 2009 to 2017 | Contextual information for disambiguation |

### Entity Aliases System ğŸ”„

```mermaid
graph TD
    BO[Barack Obama - Q76] --> EN[English Aliases]
    BO --> OL[Other Languages]
    EN --> AL1[Barack Hussein Obama II]
    EN --> AL2[Obama]
    EN --> AL3[BHO]
    EN --> AL4[President Obama]
    OL --> HI[Hindi: à¤¬à¤°à¤¾à¤• à¤“à¤¬à¤¾à¤®à¤¾]
```

### Entity Representation Details ğŸ“‘

#### English Aliases
- Barack Hussein Obama II
- Barack Obama II
- Barak Obama
- Barry Obama
- President Obama
- President Barack Obama
- BHO
- Barack
- Barack H. Obama

#### Multilingual Support
| Language | Label | Description | 
|----------|-------|-------------|
| English | Barack Obama | 44th president of the United States from 2009 to 2017 |
| Hindi | à¤¬à¤°à¤¾à¤• à¤“à¤¬à¤¾à¤®à¤¾ | à¤¸à¤‚à¤¯à¥à¤•à¥à¤¤ à¤°à¤¾à¤œà¥à¤¯ à¤…à¤®à¥‡à¤°à¤¿à¤•à¤¾ à¤•à¥‡ 44à¤µà¥‡à¤‚ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¤ªà¤¤à¤¿ |

> ğŸ” This structured approach allows Wikidata to function as a multilingual knowledge base while maintaining precise entity references.

# ğŸ“Š Knowledge Graphs: Useful but Incomplete ğŸ§©

> ğŸ’¡ While knowledge graphs provide structured information for numerous applications, they face significant challenges in comprehensive knowledge representation.

## Applications of Knowledge Graphs ğŸŒ

- ğŸ” Question answering systems
- ğŸ›’ Product search functionality
- ğŸ’¬ Dialog systems
- ğŸ“‘ Information extraction

## Key Challenges ğŸš§

- ğŸ“š **Comprehensiveness Gap**: It's not possible to manually cover all human knowledge
- â±ï¸ **Currency Problem**: Keeping information updated is extremely difficult
- ğŸ§  **Scale Limitation**: Human knowledge is vast and constantly growing

## Incompleteness Statistics ğŸ“ˆ

| Freebase Relation | % **IN**complete |
|-------------------|---------------:|
| /people/person/parents | 98.8 |
| /people/person/places_lives | 96.6 |
| /people/person/place_of_birth | 93.8 |
| /people/person/employment_history | 92.3 |
| /people/person/nationality | 78.5 |
| /people/person/education | 79.2 |

## Research Implications ğŸ”¬

- ğŸ”„ Makes **KG completion** an important task for researchers
- ğŸ”— Even essential information like parents, birthplace, and nationality are significantly incomplete
- ğŸ“Š Most relations are missing for >75% of entities

*Reference: [Min et al 2013]*

# ğŸ”„ Knowledge Graph Alignment ğŸŒ

## Entity Alignment Between Knowledge Graphs ğŸ“Š

```mermaid
graph LR
    subgraph Gâ‚[English KG]
        DC1[Daniel_Craig] --- CR[Casino Royale 2006]
        CR --- EG1[Eva_Green]
        CR --- CP[Columbia Pictures]
    end
    
    subgraph Gâ‚‚[Chinese KG]
        DC2[ä¸¹å°¼çˆ¾Â·å…‹é›·æ ¼] --- JB[007å¤§æˆ°çš‡å®¶è³­å ´]
        JB --- EG2[ä¼Šå¨ƒÂ·æ ¼é€£]
        JB --- EN[è‹±èª]
    end
    
    DC1 -.->|align| DC2
    EG1 -.->|align| EG2
```

> ğŸ’¡ The alignment matrix shows which entities correspond between different knowledge graphs (value 1.0 indicates alignment)

## Multilingual Knowledge Graph Example ğŸ—ºï¸

| KG1 (Chinese) | ğŸ”„ | KG2 (English) |
|---------------|-----|---------------|
| ç±³å¼€æœ—åŸºç½— | âŸ· | Michelangelo |
| ä½›ç½—ä¼¦è¨ | âŸ· | Florence |
| æ–‡è‰ºå¤å…´ | âŸ· | Renaissance |
| ç½—é©¬ | âŸ· | Rome |
| æ„å¤§åˆ© | âŸ· | Italy |

## Key Alignment Principles âœ…

- ğŸˆ¯ **Transliteration/Translation**: Provides initial clues for entity matching across languages
- ğŸ”„ **Neighboring Entities**: Agreement of connected entities is a strong signal for alignment
- ğŸ”— **Relation Types**: The specific relationships between neighbors may also be important 
- ğŸ§© **Holistic Approach**: Synergy between entity alignment, relation alignment, and KG completion

## Practical Applications ğŸ’¼

Entity alignment enables:
- ğŸŒ Cross-lingual knowledge transfer
- ğŸ” Enhanced search across multiple knowledge bases
- ğŸ“Š More complete knowledge representation
- ğŸ¤ Integration of information from disparate sources

# ğŸ” Knowledge Graph-based Question Answering (KGQA) ğŸ§ 

## Question Example: "What city is the Mona Lisa in?" ğŸ–¼ï¸

> ğŸ’¡ KGQA systems leverage structured knowledge and reasoning paths to answer natural language questions using multi-step inference.

## Reasoning Process âš™ï¸

```mermaid
graph TD
    A[Question: What city is the Mona Lisa in?] --> B[Disambiguate Mona Lisa]
    B --> C[Find relationships in Knowledge Graph]
    C --> D[Infer: exhibited-at + located-in]
    D --> E[Mona Lisa is in Paris]
    E --> F[Verify Paris is a city]
    F --> G[Answer: Paris]
```

### Step-by-Step Analysis ğŸ“‹

| Step | Process | Example |
|------|---------|---------|
| 1ï¸âƒ£ | **Entity Disambiguation** | Identify "Mona Lisa" as the painting |
| 2ï¸âƒ£ | **Relationship Traversal** | Mona Lisa â†’ exhibited-at â†’ The Louvre |
| 3ï¸âƒ£ | **Path Inference** | The Louvre â†’ located-in â†’ Paris |
| 4ï¸âƒ£ | **Type Verification** | Confirm Paris is a city |

## Knowledge Graph Exploration ğŸŒ

```mermaid
graph LR
    ML[Mona Lisa] -->|exhibited-at| LV[The Louvre]
    LV -->|located-in| PR[Paris]
    PR -->|capital-of| FR[France]
    LDV[Leonardo da Vinci] -->|artist| ML
    LDV -->|birthplace| AN[Anchiano]
    PR -->|located-in| ET[Eiffel Tower]
    JLM[Jean-Luc Martinez] -->|director-of| LV
    JLM -->|birthplace| PR
```

## KGQA Approaches ğŸ› ï¸

### 1. Semantic Interpretation
- ğŸ”„ Converts questions to logical forms
- ğŸ” Maps entities and relations to KG elements
- ğŸ§© Applies structured reasoning rules

### 2. End-to-End Trainable
- ğŸ¤– Uses neural networks to learn mappings directly
- ğŸ“Š Handles ambiguity through probabilistic models
- ğŸ§  Requires less explicit rule engineering

# ğŸ” Semantic Interpretation in KGQA ğŸ§ 

## Process Overview ğŸ”„

```mermaid
graph TD
    A[Natural Language Question] -->|Semantic Parsing| B[Structured Query]
    B -->|Entity Resolution| C[Resolved Query]
    C -->|Query Execution| D[Knowledge Graph]
    D --> E[Answer]
```

## Core Components ğŸ“Š

### 1ï¸âƒ£ Translation Process
> ğŸ’¡ **Translate natural language questions to structured queries cognizant of KG schema**

```sql
-- From: "What city is the Mona Lisa in?"
-- To:
select ?city where{
  ?museum is_located_in ?city.
  "mona lisa" is_exhibited_at ?museum}
```

### 2ï¸âƒ£ Entity Resolution
> ğŸ”„ Maps text references to canonical KG entity identifiers

```sql
-- After entity resolution:
select ?city where{
  ?museum is_located_in ?city.
  Q1241 is_exhibited_at ?museum}
```

### 3ï¸âƒ£ Query Execution
> ğŸ” Executes the structured query against the knowledge graph

## Characteristics of Semantic Interpretation ğŸ“‹

| Aspect | Details |
|--------|---------|
| âœ… **Pros** | ğŸ” **Interpretable**: Clear reasoning path is visible |
|  | ğŸ§© **Precise**: Follows exact KG schema and relationships |
|  | ğŸ› ï¸ **Controllable**: Query logic can be manually verified |
| âŒ **Cons** | ğŸ”„ **Implementation Complexity**: Requires sophisticated NLâ†’query translation |
|  | ğŸ§ª **Schema Dependency**: Must align with KG schema exactly |
|  | ğŸ¤– **Training Difficulty**: Not (easily) end-to-end trainable |

## Technical Components ğŸ› ï¸

1. **Natural Language Parser**
   - Identifies question type (what, where, who, when)
   - Extracts entities and relationships
   - Maps to formal query language

2. **Query Generator**
   - Constructs valid queries (SPARQL, SQL, etc.)
   - Handles query constraints and filtering

3. **Entity Linker**
   - Resolves ambiguous references
   - Maps text to KG entity IDs

> ğŸ”‘ **Key Challenge**: Bridging the semantic gap between natural language expressions and the rigid structure of knowledge graphs
# ğŸ§  "Differentiable KG" Approach to KGQA ğŸ“Š

## Neural End-to-End Architecture ğŸ”„

```mermaid
graph TD
    A[Question: "What city is the Mona Lisa in?"] --> B[Contextual Text Representation]
    G[Knowledge Graph] --> H[Graph Representation Learning]
    B --> C[Cross-Attention Network]
    H --> C
    C --> D[Answer Selection]
    D --> E[Paris]
```

## Core Components ğŸ› ï¸

### 1ï¸âƒ£ Embedding Generation
- ğŸ“ **Query Embedding**: Generate dense vector representation using BERT
  ```python
  # Pseudocode
  query_embedding = bert_encoder("What city is the Mona Lisa in?")
  ```
- ğŸŒ **Graph Embedding**: Transform KG into dense representations
  ```python
  # Pseudocode
  node_embeddings = graph_neural_network(knowledge_graph)
  ```

### 2ï¸âƒ£ Cross-Attention Mechanism
> ğŸ’¡ Creates soft alignments between question elements and graph nodes

```python
# Pseudocode for cross-attention
attention_scores = softmax(query_embedding @ node_embeddings.T)
context_vector = attention_scores @ node_embeddings
```

### 3ï¸âƒ£ Answer Selection
- ğŸ¯ Identifies which graph element(s) should be transcribed to response
- ğŸ” Uses learned parameters to rank candidate answers

## Advantages & Limitations ğŸ“‹

| âœ… Advantages | âŒ Limitations |
|--------------|---------------|
| ğŸ¤– **End-to-end trainable** | ğŸ§© **Black box reasoning** |
| ğŸ”„ **No explicit logical form needed** | ğŸ” **Limited interpretability** |
| ğŸ“ˆ **Can leverage pre-trained models** | ğŸ“Š **Requires large training data** |
| ğŸ§  **Can learn complex patterns** | ğŸ”§ **Harder to debug errors** |
| ğŸ“± **More adaptable to new domains** | ğŸ“š **May not follow explicit reasoning** |

## Technical Implementation ğŸ’»

- **Encoder Models**: BERT, RoBERTa, T5
- **Graph Models**: GCN (Graph Convolutional Networks), Graph Transformers
- **Learning Paradigm**: Supervised with answer as target entity

> ğŸ”‘ Unlike semantic parsing approaches, differentiable KG models learn to navigate the knowledge graph implicitly through neural attention mechanisms rather than through explicit query construction.
>
> # ğŸ”„ Why LLM + KG? Combining Strengths for Better AI ğŸ§ 

```mermaid
graph LR
    A[LLMs: Language & Reasoning] --- C{Integration}
    B[KGs: Factual Knowledge] --- C
    C --> D[Hybrid AI Systems]
```

## The Challenge of Dynamic Knowledge ğŸ”„

> ğŸ’¡ **Reality constantly changes**: Presidents, ministers, CEOs, and champion teams are always in flux

The factual world doesn't stand still:
- Political positions change with elections
- Company leadership rotates
- Sports champions are crowned yearly
- Geographic facts evolve (borders, populations, status)

## Parameter Space Problem ğŸ“š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Parameter Space (175B+ params)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Language Understanding       â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Reasoning Capabilities       â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Factual Knowledge            â”‚ â† Becomes outdated!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- âš ï¸ **Opaque storage**: Facts embedded deep within neural networks
- ğŸ’° **Resource intensive**: Complete retraining costs millions in compute
- ğŸ•°ï¸ **Temporal decay**: Knowledge becomes outdated after training cutoff

## The Solution: Knowledge Separation ğŸ§©

| Capability | Best Handled By | Characteristics |
|------------|----------------|-----------------|
| Language Understanding | LLM | Relatively stable |
| Reasoning | LLM | Core capability |
| Factual Knowledge | KG | Frequently changes |

## Key Benefits of Integration ğŸŒŸ

### 1ï¸âƒ£ Hallucination Prevention
- ğŸ›¡ï¸ KGs provide grounded, structured facts
- ğŸ” LLM reasoning operates on verified information
- ğŸ§ª Claims can be validated against knowledge base

### 2ï¸âƒ£ Enhanced Interpretability
- ğŸ“Š Clear knowledge provenance (source tracking)
- ğŸ”„ Transparent reasoning paths
- ğŸ§¾ Explicit citation of facts

### 3ï¸âƒ£ Practical Advantages
- ğŸ“± Easier updates (modify KG, not retrain LLM)
- ğŸ’¼ Domain-specific knowledge integration
- ğŸ”’ Improved reliability for critical applications

> ğŸ”‘ **Key Insight**: By separating the stable parts (language, reasoning) from the changing parts (facts), we create systems that are both powerful and maintainable.
